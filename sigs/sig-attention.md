## SIG简介

本SIG专注于大模型推理技术中的 Attention 技术领域。在深度学习和大模型推理的背景下，围绕Attention的计算加速成为近年来大模型推理领域的关键突破，正重塑着推理效率与资源利用的格局。如何实现高效的Attention计算成为了提升推理性能的关键因素。为了解决这一挑战，Omni Infer开源项目成立了此Attention SIG组，共同推动Attention计算在昇腾硬件平台上的创新。

## Maintainers

* Lan Longwen

## Committers

* Mao Runze
* Lu Min

## [SIG例会](meetings/sig-pd-seperation/)

可参考社区共同的[例会要求](meetings/sig-meetings-requirement.md)

例会信息：

* 会议主题：Omni-Infer社区Attention SIG例会 
* 会议时间：2025/07/24 19:00-19:30 (GMT+08:00) 中国标准时间 - 北京 
* 重复周期：2025/07/24-2025/09/30 19:00-19:30, 每两周 (周四)

点击链接入会，或添加至会议列表： https://meeting.tencent.com/dm/JN7fjLvlLoib 
* 腾讯会议：893-7292-7203

### 第一次会议议程

* Attention SIG 介绍 -- Lan Longwen
* Omni Attention技术分析 -- 毛润泽
* Chunked Attention支持计划讨论 -- 毛润泽
* 会议材料：https://gitee.com/omniai/omniinfer/issues/ICOMQP
* 其他事项


### 微信交流群
![输入图片说明](figures/attention-sig.jpg)
