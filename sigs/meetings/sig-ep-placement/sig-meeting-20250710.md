### 会议纪要

#### 1. 专家均衡优化背景与目标
- **问题背景**：MOE模型推理过程中存在专家激活的冷热不均现象，导致负载不均衡（部分GPU过载，部分闲置），影响推理性能。
- **优化目标**：通过专家摆放策略（重排与冗余部署）优化负载均衡，提升推理效率。
  - **重排策略**：基于专家亲和性与冷热特征调整部署位置。
  - **冗余策略**：为热点专家创建副本，分担负载。

#### 2. 技术实现与组件设计
- **组件架构**：
  - **核心功能**：独立组件，与推理框架解耦，通过关键点（部署、专家选择、激活统计）集成。
  - **关键模块**：
    - **集群状态管理**：专家激活频次统计、映射关系维护。
    - **优化器**：部署策略生成（贪心算法为主）、专家选择优化。
- **部署模式**：
  - **静态部署**：需人工介入（业务预热→特征采集→生成部署文件→分析验证）。
  - **动态部署**：实时采集专家热度→滑动窗口预测冷热专家→后台线程调整部署（每分钟迭代，预调整避免主流程中断）。

#### 3. 性能优化与验证
- **性能收益**：
  - **2P场景**：重排优化后单token延迟降低10%（54ms→47ms）。
  - **4P场景**：冗余部署显著提升性能，QPS达28+，QPM超425。
- **优化细节**：
  - **流水掩盖**：尝试在推理step间隔中完成调整以减少开销。
  - **收敛性**：2-3轮调整即可稳定，减少波动。
  - **低开销统计**：切流统计专家激活，避免干扰主流程。

#### 4. 未来规划
- **算法优化**：
  - **专家选择**：动态调整TOP K数量（可能少于或多于K），平衡算力与精度。
  - **部署策略**：引入静态规划迁移（全局最优替换贪心局部最优）。
- **可靠性增强**：
  - **冗余容灾**：利用多副本部署实现故障快速切换（8P场景下支持专家快速接管）。
  - **小规模部署适配**：探索更灵活的冗余方案。
- **开源进展**：
  - 静态部署代码已开源（`accelerator`目录），动态部署代码优化中即将开放。
  - 模型层适配为主，框架无关（需修改模型加载、专家选择逻辑）。

#### 5. Q&A要点
- **迁移性**：组件可独立迁移至其他框架，需对接开放接口。
- **开源代码**：静态部署代码位于主仓`accelerator`目录，动态部署待发布。
- **故障恢复**：冗余专家映射表支持快速切换，无需重构计算图。

#### 6. 社区协作
- 鼓励通过微信群、双周会议持续交流，欢迎贡献想法与代码。

### 会议录屏

会议录屏可在Omni社区[B站查看](https://www.bilibili.com/video/BV1RjuGzaEgq/)