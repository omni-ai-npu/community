本次会议同步了项目进展，并由核心开发人员技术分享了动态负载均衡方案的设计原理与实现细节。

## 小结
**1. 已取得的进展同步**
- 一批负载均衡特性已在A200硬件平台910B上运行成功。
- 已支持deepseek V3.2、Qwen-2.5及多个自研模型的知识库接入。
- 优化了placement的使用体验，实现了配置文件的统一化管理。
- 开启了在SGL框架上的集成开发。

**2. 动态负载均衡技术分享**
- **背景与方案**： 重点介绍了动态负载均衡方案，旨在通过实时收集专家激活数据，利用优化算法自动生成专家迁移指令，以达到全局最优的性能平衡。
- **关键技术细节**：
    - **核心机制**： 引入了新的后台线程独立执行优化算法，而主推理线程则负责数据采集与计算，两者通过shared value和专门的函数进行交互。
    - **专家映射**：
        - 实现了逻辑专家ID到物理设备位置的映射函数（Expert Mapping），并在大规模部署下利用矩阵乘法加速计算。
        - 通过为每一张计算卡（rank）分配一个独立线程，并设计了Rank之间的握手与同步机制，确保了同步动作和优化指令的正确执行与一致性。
    - **优化算法**： 演示了一种贪心优化算法，其特点包括：
        - **生成策略**： 鼓励优先生成“remove”指令（删除不活跃的专家占位），因其成本最低；允许生成非劣化的“add”指令。
        - **规避范围**： 在同一张卡内部进行的交换操作不会被视为潜在的性能提升，因此不予优化。
- **最终更新**：
    - 后台检查到交换指令已执行完成时，会将所有卡累积的新权重通过Buffer暂存。
    - 主线程周期性地从Buffer中读取数据，执行device-to-device的拷贝，以将最新的专家权重部署到各卡的实际工作区。

**3. 历史与优化问题回顾**
- **方案实现差异**： 优化器未使用NPU原生的logistic/softmax算子，而是自行实现映射函数，以提升灵活性。
- **数据与通信**： 专家激活值通过“moe_distribution.dispatch_view”算子直接采集；跨设备的权重交换使用了独立的通信域（通过HCCL），以减少对推理主通道的通信抢占。
- **潜在瓶颈**： 当前方案需要在显存中进行额外的数据拷贝，未来计划探索是否能在新版本中通过直接更新显存地址来避免此开销。

## 会议录屏

https://www.bilibili.com/video/BV11XyaBGEJa/ 