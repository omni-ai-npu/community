本次会议讲解了在生成芯片上实现MA算子所使用的数学算法，主要为了优化计算中的数据搬运问题。

## 小结
**1. 推理背景与核心问题**
- **背景**： 传统的冯·诺依曼架构存在数据“搬运”瓶颈（数据需从存储移动到计算单元），而存算一体芯片则试图从根本上解决此问题。
- **问题**： 在Flash Attention等高效的注意力计算框架中，由于输出结果O过大，无法常驻计算单元，每次迭代都需要将它从存储取出再放回，造成了严重的冗余数据搬运，成为性能瓶颈。

**2. 关键的数学算法：用加法替代乘法**
- 会议的核心思路是利用浮点数的内部表示规则，将乘法运算转换为原子加法，从而实现“存算一体化”，规避数据搬运。
- **原理**： 在IEEE 754标准中，浮点数的指数位可以表示2的幂。因此，一个浮点数乘以2的整数幂，可以通过在指数部分执行加法来实现。
- **实现路径**：
    - 将rescaling因子中的EXP(-MI)项，拆分为一个可被2的整数幂逼近的部分和一个独立的scale因子。
    - 让处理器在计算过程中，将符合“浮点数 x 2的整数幂”的更新项通过原子加法直接作用在现有结果上，无需物理移动数据。
    - 将拆分出来并调整过得scale因子，在后续的softmax计算步骤中直接融入，避免了额外的聚合操作。

**3. 应用范围**
- 此算法不仅适用于MLA算子，其方法论可以推广到所有涉及输出累加和乘法的算子，只要输出结果无法缓存在计算单元即可复用此技术。

## 待办
**1. Flash Attention（AMLA）社区版情况确认**
- 由于提问中提及线上同学需要注意后文是否包含此功能，需由@@(谭志强)@@跟进确认该算法是否已随开源的MA算子一同发布。