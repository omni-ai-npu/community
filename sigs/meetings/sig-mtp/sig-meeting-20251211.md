本次会议主要讨论了为跟上社区进展而进行的技术规划。议题包括通过NPU算子优化、引入近似投机和多层MTP等技术提升性能。

## 小结
**1. 维护高性能并降低社区依赖度**
- 目标是保持NPU上的高性能，同时减少与社区版本的更新鸿沟。
- 计划将当前的Torch Native实现作为过渡方案，后续的关键功能（如top-k/top-p sample等）将逐步替换为NPU算子进行实现。
- 后续组将更加活跃地参与社区，针对新功能和想法提出PR或issue。

**2. 技术方案探索与现状同步**
- **近似投机（Approximate Speculative Decoding）**： 介绍了该技术可有效提升接收率（如QWQ3B模型从53%提升至67%），同时保持模型精度。团队已关注社区相关PR的进展。
- **多层MTP**： 考虑了采用多层MTP方案的优势，即通过后续层次级修正前面层级潜在的错误，提高整体稳定性。团队已在QWQ3B模型上训练了七层MTP，正进行内部测试。

## 待办
**1. 近似投机(Patch)核开发**
- 后续将继续关注社区有关近似投机的讨论和进展。

**2. 多层MTP方案实施**
- 完成内部测试后，计划先在社区发起Issue讨论该方案。

**3. MTP模型授权**
- 若未发现问题，将会对外提供已训练好的七层MTP模型，供感兴趣的研发者提前测试。

**4. Torch Native实现优化与公开**
- 将对当前的Native实现各Kernel进行性能分析，并评估是否存在重复计算等问题以进一步优化。
- 将与团队内部讨论，决定如何面向外部公开这些优化后的实现。

## 录屏

https://www.bilibili.com/video/BV1xRmuBWEXX/ 